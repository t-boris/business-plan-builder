---
phase: 18-advanced-scenario-engine
plan: 05
type: execute
wave: 3
depends_on: ["18-02"]
files_modified:
  - src/features/scenarios/scenario-comparison.tsx
  - src/features/scenarios/decision-matrix.tsx
autonomous: true
---

<objective>
Extend scenario comparison beyond KPI metrics to include risk, timeline, and regulatory dimensions. Add weighted scoring system with rule-based recommendations.

Purpose: Transform comparison from raw metric side-by-side into a structured decision-support tool.
Output: Enhanced ScenarioComparison + new DecisionMatrix component with scoring and recommendations.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@.planning/phases/18-advanced-scenario-engine/18-02-PLAN.md

@src/features/scenarios/scenario-comparison.tsx
@src/features/scenarios/index.tsx
@src/types/scenario.ts
@src/store/scenario-atoms.ts
@src/lib/business-firestore.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Extend scenario comparison with multi-dimensional analysis</name>
  <files>src/features/scenarios/scenario-comparison.tsx</files>
  <action>
Read the current `src/features/scenarios/scenario-comparison.tsx`. It compares two scenarios on input variables and derived metrics with bar chart.

Add new comparison dimensions below the existing metrics comparison:

**1. Assumptions comparison** (new section):
- Load assumptions from both selected scenarios (via `getScenarioData` — they're stored as `assumptions[]`)
- Show side-by-side: Scenario A assumptions vs Scenario B assumptions
- Group by category if available, otherwise flat list
- Highlight assumptions unique to one scenario (not present in the other)

**2. Horizon comparison** (small info row):
- Show `horizonMonths` for each scenario: "Scenario A: 12 months | Scenario B: 24 months"
- Highlight if different

**3. Status comparison** (small badge row):
- Show status badges for each scenario

Keep the existing input variables table, derived metrics table, and bar chart. Add the new sections BELOW them.

Refactor the component to use an accordion/collapsible pattern for each comparison section:
- "Financial Metrics" (existing derived metrics) — expanded by default
- "Input Variables" (existing) — collapsed by default
- "Assumptions" (new) — collapsed by default
- "Scenario Info" (horizon + status) — collapsed by default

Use shadcn `Collapsible` or implement with simple toggle state + ChevronDown icon if Collapsible is not available in the project.
  </action>
  <verify>npm run build — passes. Comparison shows all sections with expand/collapse.</verify>
  <done>Multi-dimensional comparison with financial metrics, input variables, assumptions, and scenario info.</done>
</task>

<task type="auto">
  <name>Task 2: Create DecisionMatrix component with weighted scoring</name>
  <files>src/features/scenarios/decision-matrix.tsx</files>
  <action>
Create `src/features/scenarios/decision-matrix.tsx`.

**Props:** `canEdit: boolean`

**Data flow:**
- Read `scenarioListAtom` for available scenarios
- Load all scenarios from Firestore on mount (`listScenarioData`)
- Evaluate each scenario through formula engine

**Decision criteria model:**

```typescript
interface DecisionCriterion {
  id: string;
  label: string;
  weight: number;  // 1-10, default 5
  type: 'higher-is-better' | 'lower-is-better';
  source: 'auto' | 'manual';
  // auto: linked to a computed variable by ID
  variableId?: string;
  // manual: user provides score per scenario
  manualScores?: Record<string, number>;  // scenarioId -> score (1-10)
}
```

**Default criteria** (auto-populated from common computed variables):
- Revenue (higher-is-better, auto-linked to variable containing "revenue")
- Costs (lower-is-better, auto-linked to variable containing "cost")
- Profit (higher-is-better, auto-linked to variable containing "profit")

Users can add custom criteria with manual scoring (e.g. "Regulatory risk", "Time to market", "Team readiness").

**UI structure:**

1. **Criteria editor** (when canEdit):
   - List of criteria with weight sliders (1-10)
   - Type toggle (higher/lower is better)
   - Add custom criterion button
   - Delete criterion button

2. **Scoring matrix table:**
   - Rows: criteria
   - Columns: scenarios (all non-archived)
   - Cells: normalized scores (0-100). Auto criteria: normalize from actual values. Manual criteria: user enters 1-10 score.
   - Bottom row: **Weighted total** = sum(score * weight) / sum(weight) for each scenario

3. **Recommendation banner:**
   - Highlight the winning scenario (highest weighted total)
   - Show: "Recommended: {scenario name} (score: {total})"
   - If scores are within 5% of each other: "Close call: {A} ({scoreA}) vs {B} ({scoreB})"

**Scoring normalization for auto criteria:**
- For each criterion, find min and max across all scenarios
- Normalize to 0-100: `score = (value - min) / (max - min) * 100`
- For lower-is-better: invert: `score = 100 - score`
- If all values are equal: score = 50 for all

Store decision matrix criteria in component state (not Firestore). The matrix is a view-time computation, not persisted data.

Wire into index.tsx: Import `DecisionMatrix` and render in the Decision tab, replacing the placeholder.

Use shadcn components: `Table`, `Slider`, `Badge`, `Button`.
Import lucide icons: `Trophy`, `Plus`, `X`, `Scale`.
  </action>
  <verify>npm run build — passes. npm run lint — passes. Decision tab shows the matrix.</verify>
  <done>DecisionMatrix scores scenarios across weighted criteria with auto and manual dimensions. Recommendation displayed.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run build` succeeds
- [ ] `npm run lint` passes
- [ ] Extended comparison shows assumptions and scenario info
- [ ] Decision matrix scores scenarios correctly
- [ ] Weighted totals calculate properly
- [ ] Recommendation banner shows winner
</verification>

<success_criteria>
- Comparison view has 4 collapsible sections (metrics, inputs, assumptions, info)
- Decision matrix supports auto + manual criteria
- Weight adjustment via slider works
- Normalized scoring produces 0-100 range
- Recommendation highlights winning scenario
- All existing comparison functionality preserved
</success_criteria>

<output>
After completion, create `.planning/phases/18-advanced-scenario-engine/18-05-SUMMARY.md`
</output>
